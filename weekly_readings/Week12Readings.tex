\documentclass[12pt]{article}

\input{preamble}

\begin{document}

\begin{center}
  \textbf{Week 12 Readings} \\
  C. Hidey \\
  \today
\end{center}


\paragraph{{\bf [PIP2]Daniel Jurafsky, Rajesh Ranganath, Daniel A. McFarland (2009) }}
\text{} \\
Jurafsky et al. attempt to identify wh
in the context of speed dating

\paragraph{{\bf [PIP3] Andrew Rosenberg and Julia Hirschberg. (2008)}}
\text{} \\


\paragraph{{\bf [D1] Ott, Myle, Yejin Choi, Claire Cardie, and Jeffrey T. Hancock. 2011.}}
\text{} \\
Ott et al. attempt to detect deceptive opinions in reviews.  Because deceptive opinions are
difficult to identify, they created a dataset using Mechanical Turk and had humans generate
fake positive reviews.  They then balanced the data by sampling true reviews from TripAdvisor
according to a log-normal distribution on document length.  They evaluated human performance
and found that humans are not very good at distinguishing truthful from deceptive reviews.
They then train a machine learning classifier and find that an SVM trained with bigram features
and a deception detection toolkit (LIWC) performs much better than humans.
I liked that the paper attempts to address a novel topic and the generation of the dataset is an
interesting problem.
One issue I had with the paper is that even though it is difficult to determine truthful
reviews, the authors used 5-star reviews as gold standard truthful data.
Furthermore, they only considered n-gram features when other features might be useful as well.

\paragraph{{\bf [D2] Tommaso Fornaciari and Massimo Poesio. 2012.}}
\text{} \\
Fornaciari and Poesio study deception and take advantage of similarity between liars.  
For their data set, they used court proceedings, only including individuals that
were found guilty.  They had annotators determine whether the statements issued by
the defendants were true or false.
They used machine learning techniques and created a feature vector from n-grams for lemmas
and POS as well as from the LIWC.  
They clustered subjects according to metadata and mixed results.
They removed outliers from by clustering them according to their bag-of-words vectors
and removing the most distant subjects; this improved performance.
They repeated their experiment using only male subjects and found that it did not help
performance.
I liked that this paper uses a different standard of true and false, a scenario where
people would have real motivation to lie, although there is some question over
whether it is actual truth versus just being convicted.
I didn't like the experiment removing outliers, it seems that approach would help
any NLP task where n-grams are a feature.
\end{document}
